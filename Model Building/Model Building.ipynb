{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding CNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First CNN layer\n",
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Second CNN Layer\n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Flatten layers\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128,activation='relu'))\n",
    "model.add(Dense(units=5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 813,733\n",
      "Trainable params: 813,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Learning Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./225, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2626 images belonging to 5 classes.\n",
      "Found 1055 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory (r'C:\\Users\\Deepshika\\TRAIN_SET',target_size=(64,64),batch_size=5,color_mode='rgb',class_mode='sparse') \n",
    "x_test = train_datagen.flow_from_directory (r'C:\\Users\\Deepshika\\TEST_SET',target_size=(64,64),batch_size=5,color_mode='rgb',class_mode='sparse') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-671ee527294e>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator = x_train, steps_per_epoch = len(x_train), epochs = 20, validation_data = x_test, validation_steps = len(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "526/526 [==============================] - 23s 41ms/step - loss: 0.1654 - accuracy: 0.9379 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "526/526 [==============================] - 21s 41ms/step - loss: 5.6409e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "526/526 [==============================] - 21s 40ms/step - loss: 7.6299e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "526/526 [==============================] - 18s 34ms/step - loss: 5.2999e-05 - accuracy: 1.0000 - val_loss: 7.2984e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "526/526 [==============================] - 20s 38ms/step - loss: 2.2845e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "526/526 [==============================] - 26s 49ms/step - loss: 1.5693e-05 - accuracy: 1.0000 - val_loss: 9.2336e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "526/526 [==============================] - 24s 45ms/step - loss: 8.5315e-06 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "526/526 [==============================] - 22s 42ms/step - loss: 9.2632e-06 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "526/526 [==============================] - 22s 42ms/step - loss: 0.0772 - accuracy: 0.9787 - val_loss: 0.2698 - val_accuracy: 0.9545\n",
      "Epoch 10/20\n",
      "526/526 [==============================] - 23s 44ms/step - loss: 7.7843e-04 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9725\n",
      "Epoch 11/20\n",
      "526/526 [==============================] - 24s 45ms/step - loss: 3.7376e-05 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9763\n",
      "Epoch 12/20\n",
      "526/526 [==============================] - 24s 46ms/step - loss: 2.2467e-05 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9735\n",
      "Epoch 13/20\n",
      "526/526 [==============================] - 23s 43ms/step - loss: 1.5592e-05 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9725\n",
      "Epoch 14/20\n",
      "526/526 [==============================] - 24s 47ms/step - loss: 2.7025e-05 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9773\n",
      "Epoch 15/20\n",
      "526/526 [==============================] - 24s 46ms/step - loss: 9.2424e-06 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9763\n",
      "Epoch 16/20\n",
      "526/526 [==============================] - 24s 46ms/step - loss: 5.2953e-06 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9763\n",
      "Epoch 17/20\n",
      "526/526 [==============================] - 22s 42ms/step - loss: 3.6720e-06 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9763\n",
      "Epoch 18/20\n",
      "526/526 [==============================] - 24s 46ms/step - loss: 4.7641e-06 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9754\n",
      "Epoch 19/20\n",
      "526/526 [==============================] - 21s 41ms/step - loss: 3.4135e-06 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9773\n",
      "Epoch 20/20\n",
      "526/526 [==============================] - 24s 45ms/step - loss: 1.6362e-06 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25608bccd00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = x_train, steps_per_epoch = len(x_train), epochs = 20, validation_data = x_test, validation_steps = len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('nutrition.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "Model = load_model(\"nutrition.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = keras.utils.load_img(r\"C:\\Users\\Deepshika\\TEST_SET\\image4.jpg\", grayscale=False, target_size=(64,64))\n",
    "x = keras.utils.img_to_array(img)\n",
    "x = np.expand_dims(x,axis = 0)\n",
    "pred = Model.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['APPLES', 'BANANA', 'ORANGE', 'PINEAPPLE', 'WATERMELON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"\"\n",
    "for i in range(len(pred[0])):\n",
    "    if pred[0][i] == 1:\n",
    "        res = index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'APPLES'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
